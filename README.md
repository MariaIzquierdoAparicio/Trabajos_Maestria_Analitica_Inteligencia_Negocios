# Trabajos de la Maestría en Analítica para la Inteligencia de Negocios  
Repositorio de los trabajos realizados por **María Fernanda Izquierdo Aparicio** durante el curso de la Maestría en Analítica para la Inteligencia de Negocios (Agosto/2023 a Julio/2025)

## 📁 Estructura del repositorio (vista general)

- `Analisis de Clusters/`
- `Comparacion Modelos (KNN, SVM, Adaboost, RandomForest, CNN)/`
- `Comparacion Modelos (SVM, Reg Logistica, KNN, Random Forest, AdaBoost)/`
- `Procesamiento de Lenguaje Natural/`
- `Redes Neuronales/`
- `Regresion Lineal/`
- `Regresion Logistica/`
- `Sistemas de Recomendacion/`
- `Support Vector Machines/`

> **Tecnologías usadas en el repo (según GitHub):** Jupyter Notebook, HTML, R y un poco de Python.

---

## 🧭 Guía detallada por carpeta

### 1) `Analisis de Clusters/`
- Notebooks/cuadernos con experimentos de **agrupamiento** (k‑means, jerárquico, etc.).
- Limpieza de datos, selección/estandarización de variables, y visualizaciones de grupos.
- Métricas típicas: **inercia**, **silhouette**, dendrogramas.

### 2) `Comparacion Modelos (KNN, SVM, Adaboost, RandomForest, CNN)/`
- Comparativas de clasificadores clásicos (**KNN, SVM, AdaBoost, Random Forest**) y una referencia **CNN**.
- División entrenamiento/validación, **matriz de confusión**, **ROC/AUC**, precisión/recall/F1.
- Tablas y gráficos de performance para escoger el modelo ganador.

### 3) `Comparacion Modelos (SVM, Reg Logistica, KNN, Random Forest, AdaBoost)/`
- Otra comparativa centrada en **SVM, Regresión Logística, KNN, Random Forest y AdaBoost**.
- Enfoque en **tuning de hiperparámetros** y trade‑offs de interpretabilidad vs. desempeño.
- Reportes de métricas y curvas de validación.

### 4) `Procesamiento de Lenguaje Natural/`
- Ejercicios de **NLP**: limpieza textual, tokenización, stopwords, **lemmatización/stemming**.
- Construcción de **bolsa de palabras**, **TF‑IDF**, y modelos simples de clasificación de texto.
- Métricas de calidad y ejemplos de interpretación de resultados.

### 5) `Redes Neuronales/`
- Notebooks con redes densas/CNN básicas, funciones de activación, **early stopping**, **dropout**.
- Ciclos de entrenamiento y gráficos de **loss/accuracy**.
- Ejemplos de cómo guardar y cargar modelos.

### 6) `Regresion Lineal/`
- Modelos de regresión lineal con análisis de **supuestos** (normalidad, homocedasticidad, multicolinealidad).
- **Diagnóstico de residuos**, intervalos de confianza, interpretación de coeficientes.
- Visualizaciones de ajuste y error.

### 7) `Regresion Logistica/`
- Clasificación binaria con **regresión logística**.
- Reportes de **odds ratios**, matrices de confusión y **curvas ROC**.
- Discusión de **umbral de decisión** y calibración.

### 8) `Sistemas de Recomendacion/`
- Prototipos de **recomendadores**: filtrado colaborativo y basado en contenido.
- Cálculo de similitud, construcción de perfiles de usuario/item, y **validación cruzada**.
- Métricas: **RMSE/MAE** (rating), **precision@k / recall@k** (ranking).

### 9) `Support Vector Machines/`
- Experimentos con **SVM** (kernels lineal, RBF, etc.).
- Búsqueda de **C** y **gamma**, y visualizaciones de márgenes/soportes.
- Comparación contra otros clasificadores base.

## 🧰 Tecnologías y herramientas empleadas  
- Lenguaje de programación: **R** y **Python**
- Frameworks, librerías y paquetes típicos de análisis de datos en R y Python (se pueden consultar dentro de cada archivo).  
- Técnicas de análisis de datos: clustering, regresión (lineal y logística), sistemas de recomendación.

## 🎯 Objetivo del repositorio  
El objetivo es documentar y compartir los resultados de los distintos trabajos realizados en el marco de la Maestría. Cada carpeta contiene:  
- El **script** o cuaderno con el análisis en R/python
- Los datos (si son públicos o permitidos) o un enlace a los datos usados.  
- Un informe o presentación con conclusiones, usando metodología CRISP-DM.
- Posible documentación adicional (README interno, explicación de variables, etc.).

